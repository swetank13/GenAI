{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b207a73-2749-43aa-bf16-37652c3afdcd",
   "metadata": {},
   "source": [
    "<center><h2>Gen AI: Langchain and Prompting Essentials</h2></center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac02ab-ed8b-44af-bd8b-b15396bf3c50",
   "metadata": {},
   "source": [
    "#### 4.1: Elements of good prompt\n",
    "- Clarity and Specificity\n",
    "- Output Format\n",
    "- Context Background\n",
    "- Tone, Style & Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac3883-2100-427f-ad46-a78b3516c76f",
   "metadata": {},
   "source": [
    "#### 4.2: Zero-shot, One-shot, Few-shot Prompting\n",
    "- Zero-shot, we provide only prompt.\n",
    "- In One-shot, we provide 1 example along with prompt.\n",
    "- In Few-shot prompting, we provided few example along with prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f58e577-2257-49b3-9101-bd6e6136c02b",
   "metadata": {},
   "source": [
    "#### 4.3 & 4.4: installation of Langchain, Ollama, Groq\n",
    "- Ollama allows you to run the LLM models locally.\n",
    "- Groq allows to call LLMs in the cloud without any charges.\n",
    "- The inference (time it takes LLM to generate response) in Groq is very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61356888-6c78-4c65-a5a8-ece4b3a3fa39",
   "metadata": {},
   "source": [
    "#### 4.5: Calling LLM from Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1b8d9a-6232-403b-ae6f-9c41ac64d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain package installation guide: https://python.langchain.com/docs/how_to/installation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71dd76-4b6a-4f16-921b-578672b61b36",
   "metadata": {},
   "source": [
    "##### Load API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee269ef4-d276-477b-ac73-819cac911a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"Enter the api key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98433e09-1257-45ce-b1b2-8f0130116e96",
   "metadata": {},
   "source": [
    "##### Calling LLM in Cloud using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3b8d58-b997-4e05-a8c6-9c0301aeda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e36a868-be88-415f-940a-9b696d31386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The first person to walk on the moon was Neil Armstrong. He stepped out of the lunar module Eagle and onto the moon\\'s surface on July 20, 1969, during the Apollo 11 mission. Armstrong famously declared, \"That\\'s one small step for man, one giant leap for mankind,\" as he became the first human to set foot on the moon.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 42, 'total_tokens': 117, 'completion_time': 0.097952506, 'prompt_time': 0.01160704, 'queue_time': 0.080937394, 'total_time': 0.109559546}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--bd470ff6-c147-482a-8835-68c32c8b0ccf-0', usage_metadata={'input_tokens': 42, 'output_tokens': 75, 'total_tokens': 117})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "llm.invoke(\"The person to go to moon was\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b3e901-afec-4e5d-b909-bff4f8e19b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The first person to walk on the moon was Neil Armstrong. He stepped out', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 42, 'total_tokens': 57, 'completion_time': 0.007680503, 'prompt_time': 0.031898605, 'queue_time': 0.0496153, 'total_time': 0.039579108}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'length', 'logprobs': None}, id='run--ddfe0391-94e2-4c11-806b-2f0d9f47ee24-0', usage_metadata={'input_tokens': 42, 'output_tokens': 15, 'total_tokens': 57})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=15\n",
    ")\n",
    "llm.invoke(\"The person to go to moon was\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d72b8c-2012-4e35-a5bd-511584af01c0",
   "metadata": {},
   "source": [
    "##### Local Call to LLM Using- Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af551c81-8425-4830-834e-d0138602c070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Neil Armstrong and Edwin \"Buzz\" Aldrin were the first humans to walk', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-08-05T19:18:53.7989118Z', 'done': True, 'done_reason': 'length', 'total_duration': 3962779300, 'load_duration': 2715785800, 'prompt_eval_count': 32, 'prompt_eval_duration': 323018800, 'eval_count': 15, 'eval_duration': 922919700, 'model_name': 'llama3.2:1b'}, id='run--71f03823-32c9-4bfc-855f-c6a6faab8a30-0', usage_metadata={'input_tokens': 32, 'output_tokens': 15, 'total_tokens': 47})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\",temperature=0, num_predict=15)\n",
    "llm.invoke(\"The person to go to moon was\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f63ce-74f1-47ac-a235-5b0d80511a92",
   "metadata": {},
   "source": [
    "#### 4.6: PromptTemplate and Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44462ffe-bc89-4372-8ff1-857b9e096083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e0fd515-3bf2-4890-8fa8-ed326f6b6b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Write two line poem on {topic}')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"Write two line poem on {topic}\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4940e6b7-0a14-4653-b48c-cadbabc1ec60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A delicate butterfly dances free,\\nSpreading colorful wings, a wonder to see.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 41, 'total_tokens': 58, 'completion_time': 0.048548222, 'prompt_time': 0.011238493, 'queue_time': 0.045031857, 'total_time': 0.059786715}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6399de1f-4a8d-4104-ba1b-1b0640e0b693-0', usage_metadata={'input_tokens': 41, 'output_tokens': 17, 'total_tokens': 58})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({'topic': 'butterfly'})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90f26e4-d57c-4777-81d7-c6a0716a67d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A delicate butterfly dances free,\n",
      "Spreading colorful wings, a wonder to see.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e567d4a-dee0-44a8-b4ac-765e4215ece1",
   "metadata": {},
   "source": [
    "#### 4.7: Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67c1f225-0dbb-4197-8c77-d9a053dd184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.exceptions import OutputParserException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84255366-beb1-4539-a60f-932fdcf85402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['article'], input_types={}, partial_variables={}, template=\"\\nFrom the below news article, extract revenue and eps in JSON format containing the\\nfollowing keys: 'revenue_actual', 'revenue_expected', 'eps_actual', 'eps_expected'. \\n\\nEach value should have a unit such as million or billion.\\n\\nOnly return the valid JSON. No preamble.\\n\\nArticle\\n=======\\n{article}\\n\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = '''\n",
    "From the below news article, extract revenue and eps in JSON format containing the\n",
    "following keys: 'revenue_actual', 'revenue_expected', 'eps_actual', 'eps_expected'. \n",
    "\n",
    "Each value should have a unit such as million or billion.\n",
    "\n",
    "Only return the valid JSON. No preamble.\n",
    "\n",
    "Article\n",
    "=======\n",
    "{article}\n",
    "'''\n",
    "\n",
    "pt = PromptTemplate.from_template(prompt)\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9acc60a4-a471-44f9-9fe1-23d2fa4cf0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\")\n",
    "chain = pt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec34966d-58f0-4886-8e96-8e3323a041c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"revenue_actual\": \"25.18 billion\", \"revenue_expected\": \"25.37 billion\", \"eps_actual\": \"72 cents\", \"eps_expected\": \"58 cents\"}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text = '''\n",
    "Here’s what the company reported compared with what Wall Street was expecting, based on a survey of analysts by LSEG:\n",
    "\n",
    "Earnings per share: 72 cents, adjusted vs. 58 cents expected\n",
    "Revenue: $25.18 billion vs. $25.37 billion expected\n",
    "'''\n",
    "response = chain.invoke({'article': article_text})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3bc2a6-c55e-4791-ab60-1bd75e258c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"revenue_actual\": \"94.93 billion\", \"revenue_expected\": \"94.58 billion\", \"eps_actual\": \"1.64\", \"eps_expected\": \"1.60\"}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text = '''\n",
    "Here’s how the iPhone maker did versus LSEG consensus estimates for the quarter ending Sept. 28:  \n",
    "\n",
    "Earnings per share: $1.64, adjusted, versus $1.60 estimated \n",
    "Revenue: $94.93 billion vs. $94.58 billion estimated \n",
    "'''\n",
    "response = chain.invoke({'article': article_text})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8fb52d-7dd7-4033-853a-d27f4b4c75b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'revenue_actual': '94.93 billion',\n",
       " 'revenue_expected': '94.58 billion',\n",
       " 'eps_actual': '1.64',\n",
       " 'eps_expected': '1.60'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = JsonOutputParser()\n",
    "res = parser.parse(response.content)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d50e8605-84cd-42cc-b7c9-33db999e3e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'94.93 billion'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['revenue_actual']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
